{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d6ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5af6a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = {\n",
    "    \"train\": transforms.Compose([transforms.RandomResizedCrop(224),  # 将数据集图片放缩成224*224大小\n",
    "                                 transforms.RandomHorizontalFlip(),  # 图片有默认0.5的概率进行垂直旋转\n",
    "\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    \"test\": transforms.Compose([transforms.Resize((224, 224)),  # 调整图片大小为224*224\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6abac35d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bacterialblight': 0, 'Blast': 1, 'Brownspot': 2, 'Tungro': 3}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root=r\"C:\\Users\\dell\\Rice Leaf Disease Images\\train\",\n",
    "                                                 transform=data_transform[\"train\"])\n",
    "print(train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "554afd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bacterialblight': 0, 'Blast': 1, 'Brownspot': 2, 'Tungro': 3}\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(root=r\"C:\\Users\\dell\\Rice Leaf Disease Images\\test\",\n",
    "                                                transform=data_transform[\"test\"])\n",
    "print(test_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b857b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(dataset=train_dataset, batch_size=20,  # 将训练数据以每次20张图片的形式抽出进行训练\n",
    "                        shuffle=True, num_workers=0)\n",
    "test_data = DataLoader(dataset=test_dataset, batch_size=10,    # 将测试数据以每次10张图片的形式抽出进行测试\n",
    "                       shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d88a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1 \n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, down_sample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    " \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.down_sample = down_sample  # 定义下采样方法=传入的下采样参数\n",
    " \n",
    "    def forward(self, x):                # 正向传播过程，x为输入的特征矩阵\n",
    "        identity = x                     # 将x赋值给分支identity\n",
    "        if self.downsample is not None:  \n",
    "            identity = self.downsample(x)\n",
    " \n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    " \n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eb200d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module): \n",
    "\n",
    "    expansion = 4\n",
    " \n",
    "    def __init__(self, in_channel, out_channel, stride=1, down_sample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=1, stride=1, bias=False)  # squeeze channels\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion,\n",
    "                               kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.down_sample = down_sample\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        if self.down_sample is not None:\n",
    "            identity = self.down_sample(x)\n",
    " \n",
    "        out = self.conv1(x)   # 卷积层\n",
    "        out = self.bn1(out)   # BN层\n",
    "        out = self.relu(out)  # 激活层\n",
    " \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    " \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    " \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21d272dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, blocks_num, num_classes=1000, include_top=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 64  \n",
    " \n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 对应3*3那个maxpooling\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
    "        # conv3_x\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
    "        # conv4_x\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
    "        # conv5_x\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
    "        if self.include_top:\n",
    "\n",
    "            self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # output size = (1, 1)\n",
    "\n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        down_sample = None  # 下采样赋值为none\n",
    "\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            # 生成下采样函数\n",
    "            down_sample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion))\n",
    " \n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.in_channel, channel, down_sample=down_sample, stride=stride))\n",
    "        self.in_channel = channel * block.expansion\n",
    " \n",
    "\n",
    "        for _ in range(1, block_num):  \n",
    "\n",
    "            layers.append(block(self.in_channel, channel))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    " \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    " \n",
    "        if self.include_top:\n",
    "            x = self.avg_pool(x)     \n",
    "            x = torch.flatten(x, 1)  \n",
    "            x = self.fc(x)           \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "112c76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(num_classes=1000, include_top=True):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes, include_top=include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "787c16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(num_classes=1000, include_top=True):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top) \n",
    "def resnet50(num_classes=1000, include_top=True):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
    "def resnet101(num_classes=1000, include_top=True):\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)\n",
    "def resnet152(num_classes=1000, include_top=True):\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3], num_classes=num_classes, include_top=include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "540b3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet152()\n",
    "model_weight_path = \"./resnet152-b121ed2d.pth\"  \n",
    "assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "missing_keys, unexpected_keys = net.load_state_dict(torch.load(model_weight_path), strict=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device) \n",
    "\n",
    "epoch = 1                                           \n",
    "learning_rate = 0.001                       \n",
    "Loss_func = nn.CrossEntropyLoss()                   \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28d72de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前为第1次循环 [此次训练已进行：0/4700 0%)]\tLoss is 9.4621\n",
      "当前为第1次循环 [此次训练已进行：20/4700 0%)]\tLoss is 3.5677\n",
      "当前为第1次循环 [此次训练已进行：40/4700 1%)]\tLoss is 3.6746\n",
      "当前为第1次循环 [此次训练已进行：60/4700 1%)]\tLoss is 2.8925\n",
      "当前为第1次循环 [此次训练已进行：80/4700 2%)]\tLoss is 1.4804\n",
      "当前为第1次循环 [此次训练已进行：100/4700 2%)]\tLoss is 3.4017\n",
      "当前为第1次循环 [此次训练已进行：120/4700 3%)]\tLoss is 2.9084\n",
      "当前为第1次循环 [此次训练已进行：140/4700 3%)]\tLoss is 2.1183\n",
      "当前为第1次循环 [此次训练已进行：160/4700 3%)]\tLoss is 2.4724\n",
      "当前为第1次循环 [此次训练已进行：180/4700 4%)]\tLoss is 1.8636\n",
      "当前为第1次循环 [此次训练已进行：200/4700 4%)]\tLoss is 1.0518\n",
      "当前为第1次循环 [此次训练已进行：220/4700 5%)]\tLoss is 1.9338\n",
      "当前为第1次循环 [此次训练已进行：240/4700 5%)]\tLoss is 0.8030\n",
      "当前为第1次循环 [此次训练已进行：260/4700 6%)]\tLoss is 0.7191\n",
      "当前为第1次循环 [此次训练已进行：280/4700 6%)]\tLoss is 0.6307\n",
      "当前为第1次循环 [此次训练已进行：300/4700 6%)]\tLoss is 0.7862\n",
      "当前为第1次循环 [此次训练已进行：320/4700 7%)]\tLoss is 1.0930\n",
      "当前为第1次循环 [此次训练已进行：340/4700 7%)]\tLoss is 0.6446\n",
      "当前为第1次循环 [此次训练已进行：360/4700 8%)]\tLoss is 0.6676\n",
      "当前为第1次循环 [此次训练已进行：380/4700 8%)]\tLoss is 1.0893\n",
      "当前为第1次循环 [此次训练已进行：400/4700 9%)]\tLoss is 1.1993\n",
      "当前为第1次循环 [此次训练已进行：420/4700 9%)]\tLoss is 0.7659\n",
      "当前为第1次循环 [此次训练已进行：440/4700 9%)]\tLoss is 0.8322\n",
      "当前为第1次循环 [此次训练已进行：460/4700 10%)]\tLoss is 0.9319\n",
      "当前为第1次循环 [此次训练已进行：480/4700 10%)]\tLoss is 0.7427\n",
      "当前为第1次循环 [此次训练已进行：500/4700 11%)]\tLoss is 0.6968\n",
      "当前为第1次循环 [此次训练已进行：520/4700 11%)]\tLoss is 1.0165\n",
      "当前为第1次循环 [此次训练已进行：540/4700 11%)]\tLoss is 0.9215\n",
      "当前为第1次循环 [此次训练已进行：560/4700 12%)]\tLoss is 0.6221\n",
      "当前为第1次循环 [此次训练已进行：580/4700 12%)]\tLoss is 0.6675\n",
      "当前为第1次循环 [此次训练已进行：600/4700 13%)]\tLoss is 0.7214\n",
      "当前为第1次循环 [此次训练已进行：620/4700 13%)]\tLoss is 0.7377\n",
      "当前为第1次循环 [此次训练已进行：640/4700 14%)]\tLoss is 0.7850\n",
      "当前为第1次循环 [此次训练已进行：660/4700 14%)]\tLoss is 1.2644\n",
      "当前为第1次循环 [此次训练已进行：680/4700 14%)]\tLoss is 0.8182\n",
      "当前为第1次循环 [此次训练已进行：700/4700 15%)]\tLoss is 1.0066\n",
      "当前为第1次循环 [此次训练已进行：720/4700 15%)]\tLoss is 0.5352\n",
      "当前为第1次循环 [此次训练已进行：740/4700 16%)]\tLoss is 0.6866\n",
      "当前为第1次循环 [此次训练已进行：760/4700 16%)]\tLoss is 1.0016\n",
      "当前为第1次循环 [此次训练已进行：780/4700 17%)]\tLoss is 0.9274\n",
      "当前为第1次循环 [此次训练已进行：800/4700 17%)]\tLoss is 0.8491\n",
      "当前为第1次循环 [此次训练已进行：820/4700 17%)]\tLoss is 1.2977\n",
      "当前为第1次循环 [此次训练已进行：840/4700 18%)]\tLoss is 0.7797\n",
      "当前为第1次循环 [此次训练已进行：860/4700 18%)]\tLoss is 0.8015\n",
      "当前为第1次循环 [此次训练已进行：880/4700 19%)]\tLoss is 0.9274\n",
      "当前为第1次循环 [此次训练已进行：900/4700 19%)]\tLoss is 0.7191\n",
      "当前为第1次循环 [此次训练已进行：920/4700 20%)]\tLoss is 0.6385\n",
      "当前为第1次循环 [此次训练已进行：940/4700 20%)]\tLoss is 0.7134\n",
      "当前为第1次循环 [此次训练已进行：960/4700 20%)]\tLoss is 1.0572\n",
      "当前为第1次循环 [此次训练已进行：980/4700 21%)]\tLoss is 0.5132\n",
      "当前为第1次循环 [此次训练已进行：1000/4700 21%)]\tLoss is 0.7605\n",
      "当前为第1次循环 [此次训练已进行：1020/4700 22%)]\tLoss is 0.3899\n",
      "当前为第1次循环 [此次训练已进行：1040/4700 22%)]\tLoss is 0.9823\n",
      "当前为第1次循环 [此次训练已进行：1060/4700 23%)]\tLoss is 0.7340\n",
      "当前为第1次循环 [此次训练已进行：1080/4700 23%)]\tLoss is 0.6953\n",
      "当前为第1次循环 [此次训练已进行：1100/4700 23%)]\tLoss is 0.9831\n",
      "当前为第1次循环 [此次训练已进行：1120/4700 24%)]\tLoss is 0.7517\n",
      "当前为第1次循环 [此次训练已进行：1140/4700 24%)]\tLoss is 0.7902\n",
      "当前为第1次循环 [此次训练已进行：1160/4700 25%)]\tLoss is 0.7695\n",
      "当前为第1次循环 [此次训练已进行：1180/4700 25%)]\tLoss is 0.6199\n",
      "当前为第1次循环 [此次训练已进行：1200/4700 26%)]\tLoss is 0.7822\n",
      "当前为第1次循环 [此次训练已进行：1220/4700 26%)]\tLoss is 0.8986\n",
      "当前为第1次循环 [此次训练已进行：1240/4700 26%)]\tLoss is 0.7355\n",
      "当前为第1次循环 [此次训练已进行：1260/4700 27%)]\tLoss is 0.5768\n",
      "当前为第1次循环 [此次训练已进行：1280/4700 27%)]\tLoss is 0.8154\n",
      "当前为第1次循环 [此次训练已进行：1300/4700 28%)]\tLoss is 0.6975\n",
      "当前为第1次循环 [此次训练已进行：1320/4700 28%)]\tLoss is 0.2977\n",
      "当前为第1次循环 [此次训练已进行：1340/4700 29%)]\tLoss is 1.0058\n",
      "当前为第1次循环 [此次训练已进行：1360/4700 29%)]\tLoss is 0.5991\n",
      "当前为第1次循环 [此次训练已进行：1380/4700 29%)]\tLoss is 0.6291\n",
      "当前为第1次循环 [此次训练已进行：1400/4700 30%)]\tLoss is 0.3354\n",
      "当前为第1次循环 [此次训练已进行：1420/4700 30%)]\tLoss is 0.6843\n",
      "当前为第1次循环 [此次训练已进行：1440/4700 31%)]\tLoss is 0.6238\n",
      "当前为第1次循环 [此次训练已进行：1460/4700 31%)]\tLoss is 0.7280\n",
      "当前为第1次循环 [此次训练已进行：1480/4700 31%)]\tLoss is 0.4255\n",
      "当前为第1次循环 [此次训练已进行：1500/4700 32%)]\tLoss is 0.3243\n",
      "当前为第1次循环 [此次训练已进行：1520/4700 32%)]\tLoss is 0.9217\n",
      "当前为第1次循环 [此次训练已进行：1540/4700 33%)]\tLoss is 0.8980\n",
      "当前为第1次循环 [此次训练已进行：1560/4700 33%)]\tLoss is 0.5141\n",
      "当前为第1次循环 [此次训练已进行：1580/4700 34%)]\tLoss is 0.7256\n",
      "当前为第1次循环 [此次训练已进行：1600/4700 34%)]\tLoss is 0.7650\n",
      "当前为第1次循环 [此次训练已进行：1620/4700 34%)]\tLoss is 0.6085\n",
      "当前为第1次循环 [此次训练已进行：1640/4700 35%)]\tLoss is 0.6867\n",
      "当前为第1次循环 [此次训练已进行：1660/4700 35%)]\tLoss is 1.1960\n",
      "当前为第1次循环 [此次训练已进行：1680/4700 36%)]\tLoss is 1.2578\n",
      "当前为第1次循环 [此次训练已进行：1700/4700 36%)]\tLoss is 0.6478\n",
      "当前为第1次循环 [此次训练已进行：1720/4700 37%)]\tLoss is 0.7204\n",
      "当前为第1次循环 [此次训练已进行：1740/4700 37%)]\tLoss is 0.7210\n",
      "当前为第1次循环 [此次训练已进行：1760/4700 37%)]\tLoss is 1.2028\n",
      "当前为第1次循环 [此次训练已进行：1780/4700 38%)]\tLoss is 0.9789\n",
      "当前为第1次循环 [此次训练已进行：1800/4700 38%)]\tLoss is 1.3356\n",
      "当前为第1次循环 [此次训练已进行：1820/4700 39%)]\tLoss is 1.1927\n",
      "当前为第1次循环 [此次训练已进行：1840/4700 39%)]\tLoss is 0.7596\n",
      "当前为第1次循环 [此次训练已进行：1860/4700 40%)]\tLoss is 0.9820\n",
      "当前为第1次循环 [此次训练已进行：1880/4700 40%)]\tLoss is 0.7279\n",
      "当前为第1次循环 [此次训练已进行：1900/4700 40%)]\tLoss is 0.5540\n",
      "当前为第1次循环 [此次训练已进行：1920/4700 41%)]\tLoss is 0.7757\n",
      "当前为第1次循环 [此次训练已进行：1940/4700 41%)]\tLoss is 0.9744\n",
      "当前为第1次循环 [此次训练已进行：1960/4700 42%)]\tLoss is 0.3937\n",
      "当前为第1次循环 [此次训练已进行：1980/4700 42%)]\tLoss is 0.5549\n",
      "当前为第1次循环 [此次训练已进行：2000/4700 43%)]\tLoss is 0.6795\n",
      "当前为第1次循环 [此次训练已进行：2020/4700 43%)]\tLoss is 0.8715\n",
      "当前为第1次循环 [此次训练已进行：2040/4700 43%)]\tLoss is 0.4165\n",
      "当前为第1次循环 [此次训练已进行：2060/4700 44%)]\tLoss is 0.4993\n",
      "当前为第1次循环 [此次训练已进行：2080/4700 44%)]\tLoss is 0.8418\n",
      "当前为第1次循环 [此次训练已进行：2100/4700 45%)]\tLoss is 0.6642\n",
      "当前为第1次循环 [此次训练已进行：2120/4700 45%)]\tLoss is 0.3543\n",
      "当前为第1次循环 [此次训练已进行：2140/4700 46%)]\tLoss is 0.5854\n",
      "当前为第1次循环 [此次训练已进行：2160/4700 46%)]\tLoss is 0.2836\n",
      "当前为第1次循环 [此次训练已进行：2180/4700 46%)]\tLoss is 0.8162\n",
      "当前为第1次循环 [此次训练已进行：2200/4700 47%)]\tLoss is 0.9284\n",
      "当前为第1次循环 [此次训练已进行：2220/4700 47%)]\tLoss is 0.7919\n",
      "当前为第1次循环 [此次训练已进行：2240/4700 48%)]\tLoss is 0.6101\n",
      "当前为第1次循环 [此次训练已进行：2260/4700 48%)]\tLoss is 0.3224\n",
      "当前为第1次循环 [此次训练已进行：2280/4700 49%)]\tLoss is 0.3130\n",
      "当前为第1次循环 [此次训练已进行：2300/4700 49%)]\tLoss is 0.7728\n",
      "当前为第1次循环 [此次训练已进行：2320/4700 49%)]\tLoss is 0.6560\n",
      "当前为第1次循环 [此次训练已进行：2340/4700 50%)]\tLoss is 0.9004\n",
      "当前为第1次循环 [此次训练已进行：2360/4700 50%)]\tLoss is 1.0144\n",
      "当前为第1次循环 [此次训练已进行：2380/4700 51%)]\tLoss is 0.6771\n",
      "当前为第1次循环 [此次训练已进行：2400/4700 51%)]\tLoss is 0.8330\n",
      "当前为第1次循环 [此次训练已进行：2420/4700 51%)]\tLoss is 0.4348\n",
      "当前为第1次循环 [此次训练已进行：2440/4700 52%)]\tLoss is 0.5914\n",
      "当前为第1次循环 [此次训练已进行：2460/4700 52%)]\tLoss is 0.6072\n",
      "当前为第1次循环 [此次训练已进行：2480/4700 53%)]\tLoss is 0.6620\n",
      "当前为第1次循环 [此次训练已进行：2500/4700 53%)]\tLoss is 1.0572\n",
      "当前为第1次循环 [此次训练已进行：2520/4700 54%)]\tLoss is 0.4539\n",
      "当前为第1次循环 [此次训练已进行：2540/4700 54%)]\tLoss is 0.3431\n",
      "当前为第1次循环 [此次训练已进行：2560/4700 54%)]\tLoss is 0.9799\n",
      "当前为第1次循环 [此次训练已进行：2580/4700 55%)]\tLoss is 0.6750\n",
      "当前为第1次循环 [此次训练已进行：2600/4700 55%)]\tLoss is 0.4102\n",
      "当前为第1次循环 [此次训练已进行：2620/4700 56%)]\tLoss is 0.5599\n",
      "当前为第1次循环 [此次训练已进行：2640/4700 56%)]\tLoss is 0.6370\n",
      "当前为第1次循环 [此次训练已进行：2660/4700 57%)]\tLoss is 0.4534\n",
      "当前为第1次循环 [此次训练已进行：2680/4700 57%)]\tLoss is 0.3302\n",
      "当前为第1次循环 [此次训练已进行：2700/4700 57%)]\tLoss is 0.2842\n",
      "当前为第1次循环 [此次训练已进行：2720/4700 58%)]\tLoss is 0.6663\n",
      "当前为第1次循环 [此次训练已进行：2740/4700 58%)]\tLoss is 0.4291\n",
      "当前为第1次循环 [此次训练已进行：2760/4700 59%)]\tLoss is 0.4302\n",
      "当前为第1次循环 [此次训练已进行：2780/4700 59%)]\tLoss is 1.5236\n",
      "当前为第1次循环 [此次训练已进行：2800/4700 60%)]\tLoss is 0.7779\n",
      "当前为第1次循环 [此次训练已进行：2820/4700 60%)]\tLoss is 0.7076\n",
      "当前为第1次循环 [此次训练已进行：2840/4700 60%)]\tLoss is 0.6813\n",
      "当前为第1次循环 [此次训练已进行：2860/4700 61%)]\tLoss is 0.5449\n",
      "当前为第1次循环 [此次训练已进行：2880/4700 61%)]\tLoss is 1.1542\n",
      "当前为第1次循环 [此次训练已进行：2900/4700 62%)]\tLoss is 0.2869\n",
      "当前为第1次循环 [此次训练已进行：2920/4700 62%)]\tLoss is 0.5432\n",
      "当前为第1次循环 [此次训练已进行：2940/4700 63%)]\tLoss is 1.2227\n",
      "当前为第1次循环 [此次训练已进行：2960/4700 63%)]\tLoss is 0.6144\n",
      "当前为第1次循环 [此次训练已进行：2980/4700 63%)]\tLoss is 0.5829\n",
      "当前为第1次循环 [此次训练已进行：3000/4700 64%)]\tLoss is 0.6248\n",
      "当前为第1次循环 [此次训练已进行：3020/4700 64%)]\tLoss is 0.5382\n",
      "当前为第1次循环 [此次训练已进行：3040/4700 65%)]\tLoss is 0.7077\n",
      "当前为第1次循环 [此次训练已进行：3060/4700 65%)]\tLoss is 0.4404\n",
      "当前为第1次循环 [此次训练已进行：3080/4700 66%)]\tLoss is 0.6878\n",
      "当前为第1次循环 [此次训练已进行：3100/4700 66%)]\tLoss is 0.4805\n",
      "当前为第1次循环 [此次训练已进行：3120/4700 66%)]\tLoss is 0.6132\n",
      "当前为第1次循环 [此次训练已进行：3140/4700 67%)]\tLoss is 1.3937\n",
      "当前为第1次循环 [此次训练已进行：3160/4700 67%)]\tLoss is 0.7177\n",
      "当前为第1次循环 [此次训练已进行：3180/4700 68%)]\tLoss is 0.4025\n",
      "当前为第1次循环 [此次训练已进行：3200/4700 68%)]\tLoss is 0.3321\n",
      "当前为第1次循环 [此次训练已进行：3220/4700 69%)]\tLoss is 1.0802\n",
      "当前为第1次循环 [此次训练已进行：3240/4700 69%)]\tLoss is 0.8377\n",
      "当前为第1次循环 [此次训练已进行：3260/4700 69%)]\tLoss is 0.6594\n",
      "当前为第1次循环 [此次训练已进行：3280/4700 70%)]\tLoss is 0.4427\n",
      "当前为第1次循环 [此次训练已进行：3300/4700 70%)]\tLoss is 0.3365\n",
      "当前为第1次循环 [此次训练已进行：3320/4700 71%)]\tLoss is 0.5434\n",
      "当前为第1次循环 [此次训练已进行：3340/4700 71%)]\tLoss is 0.4021\n",
      "当前为第1次循环 [此次训练已进行：3360/4700 71%)]\tLoss is 0.1436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前为第1次循环 [此次训练已进行：3380/4700 72%)]\tLoss is 0.5295\n",
      "当前为第1次循环 [此次训练已进行：3400/4700 72%)]\tLoss is 0.3754\n",
      "当前为第1次循环 [此次训练已进行：3420/4700 73%)]\tLoss is 0.6416\n",
      "当前为第1次循环 [此次训练已进行：3440/4700 73%)]\tLoss is 0.8882\n",
      "当前为第1次循环 [此次训练已进行：3460/4700 74%)]\tLoss is 0.8922\n",
      "当前为第1次循环 [此次训练已进行：3480/4700 74%)]\tLoss is 0.5009\n",
      "当前为第1次循环 [此次训练已进行：3500/4700 74%)]\tLoss is 0.8975\n",
      "当前为第1次循环 [此次训练已进行：3520/4700 75%)]\tLoss is 0.4339\n",
      "当前为第1次循环 [此次训练已进行：3540/4700 75%)]\tLoss is 0.6826\n",
      "当前为第1次循环 [此次训练已进行：3560/4700 76%)]\tLoss is 0.4543\n",
      "当前为第1次循环 [此次训练已进行：3580/4700 76%)]\tLoss is 0.3315\n",
      "当前为第1次循环 [此次训练已进行：3600/4700 77%)]\tLoss is 0.4676\n",
      "当前为第1次循环 [此次训练已进行：3620/4700 77%)]\tLoss is 0.4845\n",
      "当前为第1次循环 [此次训练已进行：3640/4700 77%)]\tLoss is 0.3605\n",
      "当前为第1次循环 [此次训练已进行：3660/4700 78%)]\tLoss is 0.1950\n",
      "当前为第1次循环 [此次训练已进行：3680/4700 78%)]\tLoss is 0.6590\n",
      "当前为第1次循环 [此次训练已进行：3700/4700 79%)]\tLoss is 0.5262\n",
      "当前为第1次循环 [此次训练已进行：3720/4700 79%)]\tLoss is 0.8428\n",
      "当前为第1次循环 [此次训练已进行：3740/4700 80%)]\tLoss is 0.3157\n",
      "当前为第1次循环 [此次训练已进行：3760/4700 80%)]\tLoss is 0.2936\n",
      "当前为第1次循环 [此次训练已进行：3780/4700 80%)]\tLoss is 0.2652\n",
      "当前为第1次循环 [此次训练已进行：3800/4700 81%)]\tLoss is 0.5795\n",
      "当前为第1次循环 [此次训练已进行：3820/4700 81%)]\tLoss is 0.6144\n",
      "当前为第1次循环 [此次训练已进行：3840/4700 82%)]\tLoss is 0.2613\n",
      "当前为第1次循环 [此次训练已进行：3860/4700 82%)]\tLoss is 0.3878\n",
      "当前为第1次循环 [此次训练已进行：3880/4700 83%)]\tLoss is 0.2475\n",
      "当前为第1次循环 [此次训练已进行：3900/4700 83%)]\tLoss is 0.2692\n",
      "当前为第1次循环 [此次训练已进行：3920/4700 83%)]\tLoss is 0.2522\n",
      "当前为第1次循环 [此次训练已进行：3940/4700 84%)]\tLoss is 0.4097\n",
      "当前为第1次循环 [此次训练已进行：3960/4700 84%)]\tLoss is 0.6277\n",
      "当前为第1次循环 [此次训练已进行：3980/4700 85%)]\tLoss is 0.4760\n",
      "当前为第1次循环 [此次训练已进行：4000/4700 85%)]\tLoss is 0.6367\n",
      "当前为第1次循环 [此次训练已进行：4020/4700 86%)]\tLoss is 0.3807\n",
      "当前为第1次循环 [此次训练已进行：4040/4700 86%)]\tLoss is 0.6484\n",
      "当前为第1次循环 [此次训练已进行：4060/4700 86%)]\tLoss is 0.5695\n",
      "当前为第1次循环 [此次训练已进行：4080/4700 87%)]\tLoss is 0.9978\n",
      "当前为第1次循环 [此次训练已进行：4100/4700 87%)]\tLoss is 0.7459\n",
      "当前为第1次循环 [此次训练已进行：4120/4700 88%)]\tLoss is 0.3526\n",
      "当前为第1次循环 [此次训练已进行：4140/4700 88%)]\tLoss is 0.6372\n",
      "当前为第1次循环 [此次训练已进行：4160/4700 89%)]\tLoss is 0.2406\n",
      "当前为第1次循环 [此次训练已进行：4180/4700 89%)]\tLoss is 0.3478\n",
      "当前为第1次循环 [此次训练已进行：4200/4700 89%)]\tLoss is 0.3269\n",
      "当前为第1次循环 [此次训练已进行：4220/4700 90%)]\tLoss is 0.8829\n",
      "当前为第1次循环 [此次训练已进行：4240/4700 90%)]\tLoss is 0.6077\n",
      "当前为第1次循环 [此次训练已进行：4260/4700 91%)]\tLoss is 0.3023\n",
      "当前为第1次循环 [此次训练已进行：4280/4700 91%)]\tLoss is 0.8279\n",
      "当前为第1次循环 [此次训练已进行：4300/4700 91%)]\tLoss is 0.5962\n",
      "当前为第1次循环 [此次训练已进行：4320/4700 92%)]\tLoss is 0.9316\n",
      "当前为第1次循环 [此次训练已进行：4340/4700 92%)]\tLoss is 0.6743\n",
      "当前为第1次循环 [此次训练已进行：4360/4700 93%)]\tLoss is 0.4981\n",
      "当前为第1次循环 [此次训练已进行：4380/4700 93%)]\tLoss is 0.5062\n",
      "当前为第1次循环 [此次训练已进行：4400/4700 94%)]\tLoss is 0.3973\n",
      "当前为第1次循环 [此次训练已进行：4420/4700 94%)]\tLoss is 0.7554\n",
      "当前为第1次循环 [此次训练已进行：4440/4700 94%)]\tLoss is 0.3724\n",
      "当前为第1次循环 [此次训练已进行：4460/4700 95%)]\tLoss is 0.3838\n",
      "当前为第1次循环 [此次训练已进行：4480/4700 95%)]\tLoss is 0.7349\n",
      "当前为第1次循环 [此次训练已进行：4500/4700 96%)]\tLoss is 0.7506\n",
      "当前为第1次循环 [此次训练已进行：4520/4700 96%)]\tLoss is 0.3610\n",
      "当前为第1次循环 [此次训练已进行：4540/4700 97%)]\tLoss is 0.9128\n",
      "当前为第1次循环 [此次训练已进行：4560/4700 97%)]\tLoss is 0.5407\n",
      "当前为第1次循环 [此次训练已进行：4580/4700 97%)]\tLoss is 0.3482\n",
      "当前为第1次循环 [此次训练已进行：4600/4700 98%)]\tLoss is 0.3155\n",
      "当前为第1次循环 [此次训练已进行：4620/4700 98%)]\tLoss is 0.4904\n",
      "当前为第1次循环 [此次训练已进行：4640/4700 99%)]\tLoss is 0.5804\n",
      "当前为第1次循环 [此次训练已进行：4660/4700 99%)]\tLoss is 1.0341\n",
      "当前为第1次循环 [此次训练已进行：4680/4700 100%)]\tLoss is 0.3304\n",
      "\n",
      "第1次循环测试：模型损失值为：0.0639 \t 模型准确率为：77.4351%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch):\n",
    "    train_num = 0     # 训练集样本总数初始设为0\n",
    "    net.train()  # 设置模型为训练模式，保证 BN层 能够用到每一批数据的均值和方差\n",
    "    for step, (data, target) in enumerate(train_data):\n",
    "        data, target = data.to(device), target.to(device)  # 将取出的数据加载到可利用的GPU上\n",
    "        optimizer.zero_grad()                              # 清空每次循环训练的历史梯度，防止梯度累加而造成结果不收敛\n",
    "        output = net(data)                      # 将数据传入模型，通过前向传播获得预测值:\n",
    "        loss_value = Loss_func(output, target)  # 获取损失值（即计算神经网络的输出结果output与图片真实标签target的差别）\n",
    "        loss_value.backward()        # 进行反向传播：\n",
    "        optimizer.step()             # 梯度下降更新参数：\n",
    "        train_num += data.size(0)    # 统计训练集样本总数\n",
    "\n",
    "        print(f'当前为第{epoch + 1}次循环 '\n",
    "              f'[此次训练已进行：{step * len(data)}/{len(train_data.dataset)} '\n",
    "              f'{100 * step / len(train_data):.0f}%)]\\tLoss is {loss_value.item():.4f}')\n",
    "    print()\n",
    "\n",
    "    test_loss = 0.0   # 测试集的损失值初始设为0\n",
    "    test_acc = 0.0    # 测试集的准确率初始设为0\n",
    "    test_num = 0      # 测试集样本总数初始设为0\n",
    "    accuracy = 0.0\n",
    "    net.eval()        # 将模型调整为测试模型\n",
    "    with torch.no_grad():  # 清空历史梯度\n",
    "        for data, target in test_data:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = net(data)\n",
    "            loss_value2 = Loss_func(output, target)\n",
    "            _, predicted = torch.max(output.data, 1)    # 得到每行最大值（dim=1,按行进行计算）与每个最大值对应的索引值：\n",
    " \n",
    "            test_loss += loss_value2.item()                   # 每次测试得到的损失值相加\n",
    "            test_num += data.size(0)                          # 统计样本总数\n",
    "            accuracy += (predicted == target).sum().item()    # 统计经过模型测试正确的样本个数：\n",
    " \n",
    "        test_acc = 100 * accuracy / test_num                  # 计算测试集的本次循环测试后的总准确率\n",
    " \n",
    "    print(f'第{epoch+1}次循环测试：'\n",
    "          f'模型损失值为：{test_loss / test_num:.4f} \\t 模型准确率为：{test_acc:.4f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90008977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\.conda\\envs\\tf\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\dell\\.conda\\envs\\tf\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net,'./shuidao.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2b8bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Bacterialblight——白枯病', 'Blast——稻瘟病', 'Brownspot——褐斑病', 'Tungro——钨腐病']\n",
    "model = torch.load('shuidao.pth')\n",
    "model.to(device)\n",
    "image = Image.open(r'C:\\Users\\dell\\Rice Leaf Disease Images\\train\\Blast\\BLAST1_121.JPG')\n",
    "trans = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "image = image.convert(\"RGB\")\n",
    "image = trans(image)\n",
    "image = torch.unsqueeze(image, dim=0)\n",
    "\n",
    "model.eval()             \n",
    "with torch.no_grad():    \n",
    "    outputs = model(image.to(device))              \n",
    "    ans = outputs.argmax(1).clone().detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98561c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blast——稻瘟病\n"
     ]
    }
   ],
   "source": [
    "print(class_names[ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83120f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
